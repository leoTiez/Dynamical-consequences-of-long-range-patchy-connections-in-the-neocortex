{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Jupyter Notebook for the Thesis Network\n",
    "\n",
    "This notebook gives a simple plug-and-play solution to try out different parameter settings and plot different data. On the one hand, this simplifies bugfixing, but also permits to deepen the understanding of the network dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import all necessary libraries and set meta parameters, e.g. verbosity and the seed for the random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.stimulusReconstruction import fourier_trans, direct_stimulus_reconstruction\n",
    "from modules.createStimulus import *\n",
    "from modules.thesisUtils import arg_parse\n",
    "from createThesisNetwork import network_factory, NETWORK_TYPE\n",
    "from modules.networkAnalysis import mutual_information_hist, error_distance\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from webcolors import hex_to_rgb\n",
    "import nest\n",
    "\n",
    "\n",
    "VERBOSITY = 3\n",
    "nest.set_verbosity(\"M_ERROR\")\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define all parameters of our network. First, we set the network type and the type of input we want to use. Then we define the actual network parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_type=NETWORK_TYPE[\"local_circ_patchy_sd\"]\n",
    "input_type=INPUT_TYPE[\"perlin\"]\n",
    "\n",
    "simulation_time = 1000.\n",
    "num_neurons = int(1e3)  # Number of neurons in the sheet with sensory neurons\n",
    "cap_s = 1.  # Weight of excitatory recurrent synapses\n",
    "inh_weight = -15.  # Weight of inhibitory recurrent synapses\n",
    "all_same_input_current = False  # Flag is set to True if all sensory neurons should receive the same ff input\n",
    "p_loc = 0.6  # Connection probability of local connections\n",
    "p_lr = 0.2  # Connection probability of long-range connections\n",
    "p_rf = 0.7  # Connection probability with neurons in the receptive field\n",
    "pot_threshold = -55.  # Threshold potential  \n",
    "pot_reset = -70.  # Reset potential\n",
    "capacitance = 80.  # Capacitance\n",
    "time_constant = 20.  # Time constant\n",
    "use_continuous_tuning = False  # Flag to determine the stimulus tuning function that should be used "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following line, we load the input stimulus, meaning the type of image we have defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_stimulus = stimulus_factory(input_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network is created through a factory interface to simplify the creation process. It returns network object, which establishes the connections, receptive fields and orientation map through the function call `network.create_network()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = network_factory(\n",
    "    input_stimulus,\n",
    "    network_type=network_type,\n",
    "    num_sensory=num_neurons,\n",
    "    all_same_input_current=all_same_input_current,\n",
    "    cap_s=cap_s,\n",
    "    inh_weight=inh_weight,\n",
    "    p_loc=p_loc,\n",
    "    p_lr=p_lr,\n",
    "    verbosity=VERBOSITY\n",
    ")\n",
    "network.create_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To investigate the response we simulate the network for a given time. The return parameters of the simulation function are the firing rates of every neuron, which neurons spiked in chronological order and the respective spike times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_rates, (spikes_s, time_s) = network.simulate(simulation_time)\n",
    "\n",
    "if VERBOSITY > 0:\n",
    "    average_firing_rate = np.mean(firing_rates)\n",
    "    print(\"\\n#####################\\tAverage firing rate: %s\" % average_firing_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If required, it's possible to plot the neural response coloured with respect to their respective stimulus tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VERBOSITY > 2:\n",
    "    print(\"\\n#####################\\tPlot firing pattern over time\")\n",
    "    positions = np.asarray(tp.GetPosition(spikes_s.tolist()))\n",
    "    plot_colorbar(plt.gcf(), plt.gca(), num_stim_classes=network.num_stim_discr)\n",
    "\n",
    "    inh_mask = np.zeros(len(spikes_s)).astype('bool')\n",
    "    for inh_n in network.torus_inh_nodes:\n",
    "        inh_mask[spikes_s == inh_n] = True\n",
    "\n",
    "    x_grid, y_grid = coordinates_to_cmap_index(network.layer_size, positions[~inh_mask], network.spacing_perlin)\n",
    "    stim_classes = network.color_map[x_grid, y_grid]\n",
    "    c = np.full(len(spikes_s), '#000000')\n",
    "    c[~inh_mask] = np.asarray(list(mcolors.TABLEAU_COLORS.items()))[stim_classes, 1]\n",
    "    plt.scatter(time_s, spikes_s, c=c.tolist(), marker=',')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network response can be plotted with respect to space. This means that the neurons with a high firing rate are plotted opaquely, whereas neurons that exhibit only a low firing rate are depicted more transparently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VERBOSITY > 2:\n",
    "    print(\"\\n#####################\\tPlot firing pattern over space\")\n",
    "    plot_colorbar(plt.gcf(), plt.gca(), num_stim_classes=network.num_stim_discr)\n",
    "\n",
    "    inh_mask = np.zeros(len(network.torus_layer_nodes)).astype('bool')\n",
    "    inh_mask[np.asarray(network.torus_inh_nodes) - min(network.torus_layer_nodes)] = True\n",
    "\n",
    "    x_grid, y_grid = coordinates_to_cmap_index(\n",
    "        network.layer_size,\n",
    "        np.asarray(network.torus_layer_positions)[~inh_mask],\n",
    "        network.spacing_perlin\n",
    "    )\n",
    "    stim_classes = network.color_map[x_grid, y_grid]\n",
    "\n",
    "    c = np.full(len(network.torus_layer_nodes), '#000000')\n",
    "    c[~inh_mask] = np.asarray(list(mcolors.TABLEAU_COLORS.items()))[stim_classes, 1]\n",
    "\n",
    "    c_rgba = np.zeros((len(network.torus_layer_nodes), 4))\n",
    "    for num, color in enumerate(c):\n",
    "        c_rgba[num, :3] = np.asarray(hex_to_rgb(color))[:] / 255.\n",
    "    c_rgba[:, 3] = firing_rates/float(max(firing_rates))\n",
    "    plt.scatter(\n",
    "        np.asarray(network.torus_layer_positions)[:, 0],\n",
    "        np.asarray(network.torus_layer_positions)[:, 1],\n",
    "        c=c_rgba\n",
    "    )\n",
    "    \n",
    "    plt.imshow(\n",
    "        network.color_map,\n",
    "        cmap=custom_cmap(),\n",
    "        alpha=0.3,\n",
    "        origin=(network.color_map.shape[0] // 2, network.color_map.shape[1] // 2),\n",
    "        extent=(\n",
    "            -network.layer_size / 2.,\n",
    "            network.layer_size / 2.,\n",
    "            -network.layer_size / 2.,\n",
    "            network.layer_size / 2.\n",
    "        )\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to reconstruct the original stimulus. So far, this has been done through weighting the respective tuning with the firing rate. However, it can be assumed that information is lost through non-linearities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #################################################################################################################\n",
    "# Reconstruct stimulus\n",
    "# #################################################################################################################\n",
    "# Reconstruct input stimulus\n",
    "if VERBOSITY > 0:\n",
    "    print(\"\\n#####################\\tReconstruct stimulus\")\n",
    "    \n",
    "mask = None\n",
    "reconstruction = direct_stimulus_reconstruction(\n",
    "    firing_rates[mask],\n",
    "    network.ff_weight_mat[:, mask],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the verbosity flag is set high enought the reconstructed image is displayed together with the original input and the orientation map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VERBOSITY > 1:\n",
    "    _, fig_2 = plt.subplots(1, 3)\n",
    "    fig_2[0].imshow(reconstruction, cmap='gray')\n",
    "    fig_2[1].imshow(input_stimulus, cmap='gray', vmin=0, vmax=255)\n",
    "    fig_2[2].imshow(network.color_map, cmap=custom_cmap())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
